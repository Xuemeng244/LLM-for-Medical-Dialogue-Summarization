{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9691403-d603-4c0b-8ae4-fbfaead8a086",
   "metadata": {},
   "source": [
    "## Step 1 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b53dc897-d035-489c-8a15-676b235ef123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jie/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import json\n",
    "from datasets import *\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import Trainer, TrainingArguments,  DataCollatorForLanguageModeling, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from tqdm import tqdm\n",
    "from rouge_score import rouge_scorer\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForSeq2SeqLM, AdamW, get_scheduler\n",
    "import pandas as pd\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b2df79",
   "metadata": {},
   "source": [
    "## Step 2 Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "086f4e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedicalDialogueDataset(Dataset):\n",
    "    def __init__(self, split, percent=100, seed=42):  # 添加seed参数，默认值为42\n",
    "        # Load data set\n",
    "        ds = load_dataset(\"omi-health/medical-dialogue-to-soap-summary\", split=split)\n",
    "        \n",
    "        # Remove unwanted columns\n",
    "        columns_to_remove = ['messages', 'prompt']\n",
    "        ds = ds.remove_columns(columns_to_remove)\n",
    "        \n",
    "        # Replace line breaks and rename columns\n",
    "        ds = ds.rename_column('soap', 'summary')\n",
    "        \n",
    "        # Add the ID and format the digest\n",
    "        ds = ds.map(self.add_id, with_indices=True)\n",
    "        ds = ds.map(self.format_summary)\n",
    "        \n",
    "        # Select the corresponding percentage\n",
    "        if percent < 100:\n",
    "            ds = ds.shuffle(seed=seed).select(range(int(percent / 100.0 * len(ds))))\n",
    "        \n",
    "        self.data = ds\n",
    "    \n",
    "    def add_id(self, example, idx):\n",
    "        example['id'] = str(idx)\n",
    "        return example\n",
    "    \n",
    "    def format_summary(self, example):\n",
    "        example['summary'] = example['summary'].replace('S: ', 'Subjective: ')\n",
    "        example['summary'] = example['summary'].replace('O: ', 'Objective: ')\n",
    "        example['summary'] = example['summary'].replace('A: ', 'Assessment: ')\n",
    "        example['summary'] = example['summary'].replace('P: ', 'Plan: ')\n",
    "        return example\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]  # 获取索引对应的数据项\n",
    "        ordered_item = {'id': item['id']}  # 创建一个新字典，并首先加入'id'\n",
    "        ordered_item.update({k: item[k] for k in item if k != 'id'})  # 添加其他字段，排除'id'\n",
    "        # return item['dialogue'], item['summary'] \n",
    "        return ordered_item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a743f4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 9250/9250 [00:00<00:00, 28998.10 examples/s]\n",
      "Map: 100%|██████████| 9250/9250 [00:00<00:00, 22349.39 examples/s]\n",
      "Map: 100%|██████████| 500/500 [00:00<00:00, 17040.32 examples/s]\n",
      "Map: 100%|██████████| 500/500 [00:00<00:00, 21214.00 examples/s]\n",
      "Map: 100%|██████████| 250/250 [00:00<00:00, 12515.83 examples/s]\n",
      "Map: 100%|██████████| 250/250 [00:00<00:00, 19958.05 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create training dataset instances of different percentages\n",
    "train_data = MedicalDialogueDataset('train', percent=20, seed=42)\n",
    "# train_data = MedicalDialogueDataset('train', percent=50, seed=42)\n",
    "# train_data = MedicalDialogueDataset('train', percent=100, seed=42)  \n",
    "\n",
    "valid_data = MedicalDialogueDataset('validation')\n",
    "test_data = MedicalDialogueDataset('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60c941c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: 1850\n",
      "valid set size: 500\n",
      "test set size: 250\n",
      "{'id': '8647', 'dialogue': \"Doctor: Good morning, how can I help you today?\\nPatient: Hi doctor, I recently underwent an abdominal ultrasonography (USG) for my bilateral renal nephrolithiasis.\\nDoctor: I see. Tell me about your general health. How is your blood biochemistry, and do you have any cardiovascular or hormonal disorders?\\nPatient: My blood biochemistry is normal, and I don't have any cardiovascular or hormonal disorders. I had an operation 17 years ago to repair my extrophic bladder, and they created an Indiana pouch for me.\\nDoctor: Alright. Can you tell me about your weight and body mass index (BMI)?\\nPatient: My weight is 85 kg, and my BMI is 28.7 kg/m2.\\nDoctor: Thank you for the information. Now, let's talk about your USG results. It showed a hyperechogenic lesion at the fat intensity, filling out your right renal sinus completely. A computerized tomography (CT) scan confirmed the presence of a fatty mass that extended from the renal sinus down to the pelvis cuffing the right ureter throughout its entire length with severe hydronephrosis. Your left kidney seems unremarkable, except for a small scar at the upper pole. There's a suspicion for liposarcoma due to the presence of high-density regions inside the lesion. \\nPatient: Oh no, that sounds serious. What can be done about it?\\nDoctor: The best course of action was to perform a resection of the mass with right radical nephroureterectomy, which has already been done. The tumor was 16x13x6 cm in size, fatty in appearance, and marbled with irregular whitish solid areas or fibrosis. The entrapped ureter was stenotic proximally and distally, but dilated at its middle part. Your kidney was hydronephrotic with thinned out atrophic parenchyma, and a few small stones were detected inside the collecting system.\\nPatient: What did the microscopic examination of the tumor show?\\nDoctor: The microscopic examination showed mature fat tissue devoid of normal architecture, owing to expanded interstitial spaces either because of intense edema or irregular fibrous streaks. Fibrous septa between fat lobules contained mildly increased numbers of stromal fibroblasts, fine collagen, vascular proliferation, multifocal lymphocytic infiltration, occasional lymphoid follicles, and foamy histiocytes. Plasma cells were rare, and immunohistochemistry showed only a <2% IgG4+/ IgG+ plasma cell ratio. There were also scattered smooth muscle bundles, usually in close association with vessels. Ectatic branching lymphatic channels were not noted, and there were neither lipoblasts nor significant cellular atypia. A few scattered fibroblasts carried multilobulated large nuclei.\\nPatient: So, what does all of this mean for me?\\nDoctor: Your results indicate that the tumor has been successfully removed, and there are no signs of aggressive cancer. However, it is essential to monitor your condition and attend regular follow-up appointments to ensure everything remains stable.\\nPatient: Thank you, doctor. I'll make sure to schedule those follow-up appointments and keep an eye on my health.\\nDoctor: You're welcome. If you have any concerns or notice any changes in your health, please don't hesitate to contact me or schedule an appointment. Take care!\", 'summary': \"Subjective: The patient reported undergoing an abdominal ultrasonography for bilateral renal nephrolithiasis. He has a history of extrophic bladder repair with an Indiana pouch created 17 years ago. He denies any cardiovascular or hormonal disorders. His chief complaint relates to findings from recent imaging studies indicating a significant renal issue.\\nObjective: The patient's weight is 85 kg, and his BMI is 28.7 kg/m2. Blood biochemistry is within normal limits. Abdominal ultrasonography and CT scan revealed a hyperechogenic lesion at the fat intensity in the right renal sinus, extending to the pelvis and cuffing the right ureter, causing severe hydronephrosis. The left kidney shows a small scar but is otherwise unremarkable. A right radical nephroureterectomy was performed, removing a 16x13x6 cm fatty mass with features suggestive of liposarcoma. Microscopic examination showed mature fat tissue with expanded interstitial spaces, mild stromal fibroblast increase, and no significant cellular atypia or lipoblasts.\\nAssessment: The primary diagnosis is a benign fatty tumor of the right kidney with severe hydronephrosis and renal atrophy, likely secondary to the mass effect and chronic obstruction. Differential diagnosis included liposarcoma, which was ruled out based on histopathological findings. The prognosis is good following surgical resection, but regular monitoring is necessary to detect any recurrence or new complications.\\nPlan: The patient is advised to schedule regular follow-up appointments for monitoring his renal function and to detect any signs of recurrence early. He should maintain a healthy diet and hydration to support kidney function. Any new symptoms or changes in health should prompt an immediate consultation. Further consultations with a nephrologist and a urologist may be necessary to manage long-term outcomes and monitor renal function.\", 'messages_nosystem': [{'role': 'user', 'content': \"You are an expert medical professor assisting in the creation of medically accurate SOAP summaries. Please ensure the response follows the structured format: S:, O:, A:, P: without using markdown or special formatting. Create a Medical SOAP note summary from the dialogue, following these guidelines:\\n    S (Subjective): Summarize the patient's reported symptoms, including chief complaint and relevant history. Rely on the patient's statements as the primary source and ensure standardized terminology.\\n    O (Objective): Highlight critical findings such as vital signs, lab results, and imaging, emphasizing important details like the side of the body affected and specific dosages. Include normal ranges where relevant.\\n    A (Assessment): Offer a concise assessment combining subjective and objective data. State the primary diagnosis and any differential diagnoses, noting potential complications and the prognostic outlook.\\n    P (Plan): Outline the management plan, covering medication, diet, consultations, and education. Ensure to mention necessary referrals to other specialties and address compliance challenges.\\n    Considerations: Compile the report based solely on the transcript provided. Maintain confidentiality and document sensitively. Use concise medical jargon and abbreviations for effective doctor communication.\\n    Please format the summary in a clean, simple list format without using markdown or bullet points. Use 'S:', 'O:', 'A:', 'P:' directly followed by the text. Avoid any styling or special characters. ### Dialogue:\\nDoctor: Good morning, how can I help you today?\\nPatient: Hi doctor, I recently underwent an abdominal ultrasonography (USG) for my bilateral renal nephrolithiasis.\\nDoctor: I see. Tell me about your general health. How is your blood biochemistry, and do you have any cardiovascular or hormonal disorders?\\nPatient: My blood biochemistry is normal, and I don't have any cardiovascular or hormonal disorders. I had an operation 17 years ago to repair my extrophic bladder, and they created an Indiana pouch for me.\\nDoctor: Alright. Can you tell me about your weight and body mass index (BMI)?\\nPatient: My weight is 85 kg, and my BMI is 28.7 kg/m2.\\nDoctor: Thank you for the information. Now, let's talk about your USG results. It showed a hyperechogenic lesion at the fat intensity, filling out your right renal sinus completely. A computerized tomography (CT) scan confirmed the presence of a fatty mass that extended from the renal sinus down to the pelvis cuffing the right ureter throughout its entire length with severe hydronephrosis. Your left kidney seems unremarkable, except for a small scar at the upper pole. There's a suspicion for liposarcoma due to the presence of high-density regions inside the lesion. \\nPatient: Oh no, that sounds serious. What can be done about it?\\nDoctor: The best course of action was to perform a resection of the mass with right radical nephroureterectomy, which has already been done. The tumor was 16x13x6 cm in size, fatty in appearance, and marbled with irregular whitish solid areas or fibrosis. The entrapped ureter was stenotic proximally and distally, but dilated at its middle part. Your kidney was hydronephrotic with thinned out atrophic parenchyma, and a few small stones were detected inside the collecting system.\\nPatient: What did the microscopic examination of the tumor show?\\nDoctor: The microscopic examination showed mature fat tissue devoid of normal architecture, owing to expanded interstitial spaces either because of intense edema or irregular fibrous streaks. Fibrous septa between fat lobules contained mildly increased numbers of stromal fibroblasts, fine collagen, vascular proliferation, multifocal lymphocytic infiltration, occasional lymphoid follicles, and foamy histiocytes. Plasma cells were rare, and immunohistochemistry showed only a <2% IgG4+/ IgG+ plasma cell ratio. There were also scattered smooth muscle bundles, usually in close association with vessels. Ectatic branching lymphatic channels were not noted, and there were neither lipoblasts nor significant cellular atypia. A few scattered fibroblasts carried multilobulated large nuclei.\\nPatient: So, what does all of this mean for me?\\nDoctor: Your results indicate that the tumor has been successfully removed, and there are no signs of aggressive cancer. However, it is essential to monitor your condition and attend regular follow-up appointments to ensure everything remains stable.\\nPatient: Thank you, doctor. I'll make sure to schedule those follow-up appointments and keep an eye on my health.\\nDoctor: You're welcome. If you have any concerns or notice any changes in your health, please don't hesitate to contact me or schedule an appointment. Take care!\"}, {'role': 'assistant', 'content': \"S: The patient reported undergoing an abdominal ultrasonography for bilateral renal nephrolithiasis. He has a history of extrophic bladder repair with an Indiana pouch created 17 years ago. He denies any cardiovascular or hormonal disorders. His chief complaint relates to findings from recent imaging studies indicating a significant renal issue.\\nO: The patient's weight is 85 kg, and his BMI is 28.7 kg/m2. Blood biochemistry is within normal limits. Abdominal ultrasonography and CT scan revealed a hyperechogenic lesion at the fat intensity in the right renal sinus, extending to the pelvis and cuffing the right ureter, causing severe hydronephrosis. The left kidney shows a small scar but is otherwise unremarkable. A right radical nephroureterectomy was performed, removing a 16x13x6 cm fatty mass with features suggestive of liposarcoma. Microscopic examination showed mature fat tissue with expanded interstitial spaces, mild stromal fibroblast increase, and no significant cellular atypia or lipoblasts.\\nA: The primary diagnosis is a benign fatty tumor of the right kidney with severe hydronephrosis and renal atrophy, likely secondary to the mass effect and chronic obstruction. Differential diagnosis included liposarcoma, which was ruled out based on histopathological findings. The prognosis is good following surgical resection, but regular monitoring is necessary to detect any recurrence or new complications.\\nP: The patient is advised to schedule regular follow-up appointments for monitoring his renal function and to detect any signs of recurrence early. He should maintain a healthy diet and hydration to support kidney function. Any new symptoms or changes in health should prompt an immediate consultation. Further consultations with a nephrologist and a urologist may be necessary to manage long-term outcomes and monitor renal function.\"}]}\n"
     ]
    }
   ],
   "source": [
    "print(f'train set size: {len(train_data)}')\n",
    "print(f'valid set size: {len(valid_data)}')\n",
    "print(f'test set size: {len(test_data)}')\n",
    "print(next(iter(train_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1bc07f",
   "metadata": {},
   "source": [
    "## Step 3 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5559b5",
   "metadata": {},
   "source": [
    "Choose one of the following models to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05921991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ec5a9c",
   "metadata": {},
   "source": [
    "### bart-large-text-summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d1a2e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jie/.local/lib/python3.8/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "max_input_length = 512\n",
    "max_target_length = 256\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Azma-AI/bart-large-text-summarizer\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Azma-AI/bart-large-text-summarizer\")\n",
    "# Transfer the model to the GPU and convert to semi-precision\n",
    "model = model.to(device).half()\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c52f87",
   "metadata": {},
   "source": [
    "### bart-large-xsum-samsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152a0f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 512\n",
    "max_target_length = 256\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"lidiya/bart-large-xsum-samsum\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"lidiya/bart-large-xsum-samsum\").to(device).half()\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5051a9",
   "metadata": {},
   "source": [
    "### ssr-base-finetuned-samsum-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d9d8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 512\n",
    "max_target_length = 256\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"santiviquez/ssr-base-finetuned-samsum-en\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"santiviquez/ssr-base-finetuned-samsum-en\").to(device).half()\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce2754c",
   "metadata": {},
   "source": [
    "### T5-Finetuned-Summarization-DialogueDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424fe7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 512\n",
    "max_target_length = 256\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gauravkoradiya/T5-Finetuned-Summarization-DialogueDataset\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"gauravkoradiya/T5-Finetuned-Summarization-DialogueDataset\").half()\n",
    "model = model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "523d179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collote_fn(batch_samples):\n",
    "    batch_inputs, batch_targets = [], []\n",
    "    for sample in batch_samples:\n",
    "        batch_inputs.append(sample['dialogue'])\n",
    "        batch_targets.append(sample['summary'])\n",
    "    batch_data = tokenizer(\n",
    "        batch_inputs, \n",
    "        padding=True, \n",
    "        max_length=max_input_length,\n",
    "        truncation=True, \n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            batch_targets, \n",
    "            padding=True, \n",
    "            max_length=max_target_length,\n",
    "            truncation=True, \n",
    "            return_tensors=\"pt\"\n",
    "        )[\"input_ids\"]\n",
    "        batch_data['decoder_input_ids'] = model.prepare_decoder_input_ids_from_labels(labels)\n",
    "        end_token_index = torch.where(labels == tokenizer.eos_token_id)[1]\n",
    "        for idx, end_idx in enumerate(end_token_index):\n",
    "            labels[idx][end_idx+1:] = -100\n",
    "        batch_data['labels'] = labels\n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a4c2710",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=4, shuffle=True, collate_fn=collote_fn)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=4, shuffle=False, collate_fn=collote_fn)\n",
    "test_dataloader = DataLoader(test_data, batch_size=4,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff31b82",
   "metadata": {},
   "source": [
    "Evaluate the data set before fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63ee7488",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Summaries: 100%|██████████| 63/63 [02:16<00:00,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE Scores: {'rouge1': 0.25684714494565014, 'rouge2': 0.12714116561972183, 'rougeL': 0.18907099419037057}\n",
      "Pre-training predictions and ROUGE scores saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "def predict_summary(dialogue, model, tokenizer):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(dialogue, return_tensors=\"pt\", padding=True, truncation=True, max_length=1024).to(device)\n",
    "        outputs = model.generate(inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], max_length=512)\n",
    "        summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "results = []\n",
    "rouge_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "for batch in tqdm(test_dataloader, desc=\"Generating Summaries\"):\n",
    "    dialogues = batch['dialogue']\n",
    "    reference_summaries = batch['summary']\n",
    "    \n",
    "    for dialogue, reference_summary in zip(dialogues, reference_summaries):\n",
    "        predicted_summary = predict_summary(dialogue, model, tokenizer)\n",
    "        scores = scorer.score(reference_summary, predicted_summary)\n",
    "        results.append({\n",
    "            \"Dialogue\": dialogue,\n",
    "            \"Reference Summary\": reference_summary,\n",
    "            \"Predicted Summary\": predicted_summary,\n",
    "            \"ROUGE-1\": scores['rouge1'].fmeasure,\n",
    "            \"ROUGE-2\": scores['rouge2'].fmeasure,\n",
    "            \"ROUGE-L\": scores['rougeL'].fmeasure\n",
    "        })\n",
    "\n",
    "        # Accumulate scores\n",
    "        rouge_scores['rouge1'].append(scores['rouge1'].fmeasure)\n",
    "        rouge_scores['rouge2'].append(scores['rouge2'].fmeasure)\n",
    "        rouge_scores['rougeL'].append(scores['rougeL'].fmeasure)\n",
    "\n",
    "# Calculate the average ROUGE score\n",
    "average_scores = {key: sum(values) / len(values) for key, values in rouge_scores.items()}\n",
    "print(\"Average ROUGE Scores:\", average_scores)\n",
    "\n",
    "# Save to JSON file\n",
    "with open('pre_bart_large_text_summarizer.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Pre-training predictions and ROUGE scores saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e4fa2d",
   "metadata": {},
   "source": [
    "Convert the JSON file to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bdfa5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'pre_bart_large_text_summarizer'\n",
    "# model_name = 'pre_bart_large_xsum_samsum'\n",
    "# model_name = 'pre_ssr_base_finetuned_samsum'\n",
    "# model_name = 'pre_T5_finetuned_summarization_DialogueDataset'\n",
    "results = []\n",
    "for idx in range(len(test_data)):\n",
    "    try:\n",
    "        dialogue, reference_summary = test_data[idx]\n",
    "        predicted_summary = predict_summary(dialogue, model, tokenizer)\n",
    "        results.append({\n",
    "            \"Dialogue\": dialogue,\n",
    "            \"Reference Summary\": reference_summary,\n",
    "            \"Predicted Summary\": predicted_summary\n",
    "        })\n",
    "    except ValueError as e:\n",
    "        print(f\"Error at index {idx}: {e}\")\n",
    "\n",
    "\n",
    "# 保存到CSV\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(f\"{model_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6080b9b2",
   "metadata": {},
   "source": [
    "Since the AutoModelForSeq2SeqLM function that comes with the Transformers library is used to build the model directly here, I process the data in each batch into a format acceptable to the model: A dictionary containing the keys 'attention_mask', 'input_ids', 'labels' and 'decoder_input_ids'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6300f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'decoder_input_ids', 'labels'])\n",
      "batch shape: {'input_ids': torch.Size([4, 512]), 'attention_mask': torch.Size([4, 512]), 'decoder_input_ids': torch.Size([4, 256]), 'labels': torch.Size([4, 256])}\n",
      "{'input_ids': tensor([[    0, 41152,    35,  ...,    83,   314,     2],\n",
      "        [    0, 41152,    35,  ...,     1,     1,     1],\n",
      "        [    0, 41152,    35,  ...,  1848,   783,     2],\n",
      "        [    0, 41152,    35,  ...,     8,    21,     2]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), 'decoder_input_ids': tensor([[    2,     0, 47159,  ...,  5929, 44030,  4866],\n",
      "        [    2,     0, 47159,  ...,  1233,  3855,    11],\n",
      "        [    2,     0, 47159,  ...,   119,  3964, 44704],\n",
      "        [    2,     0, 47159,  ..., 27225,  7168,   618]]), 'labels': tensor([[    0, 47159,  2088,  ..., 44030,  4866,     2],\n",
      "        [    0, 47159,  2088,  ...,  3855,    11,     2],\n",
      "        [    0, 47159,  2088,  ...,  3964, 44704,     2],\n",
      "        [    0, 47159,  2088,  ...,  7168,   618,     2]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jie/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:4016: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "print(batch.keys())\n",
    "print('batch shape:', {k: v.shape for k, v in batch.items()})\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b42f86",
   "metadata": {},
   "source": [
    "## Step 4 Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5b0d1c",
   "metadata": {},
   "source": [
    "The model constructed by AutoModelForSeq2SeqLM has been packaged with the corresponding loss function, and the calculated loss will be directly included in the outputs of the model, which can be obtained directly through outputs.loss, so the training cycle is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49079eda-9572-48a6-8f20-b162e0026f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_loop(dataloader, model, optimizer, lr_scheduler, epoch, total_loss):\n",
    "    progress_bar = tqdm(range(len(dataloader)))\n",
    "    progress_bar.set_description(f'loss: {0:>7f}')\n",
    "    finish_batch_num = (epoch-1) * len(dataloader)\n",
    "    \n",
    "    model.train()\n",
    "    for batch, batch_data in enumerate(dataloader, start=1):\n",
    "        batch_data = batch_data.to(device)\n",
    "        outputs = model(**batch_data)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_description(f'loss: {total_loss/(finish_batch_num + batch):>7f}')\n",
    "        progress_bar.update(1)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d494882b",
   "metadata": {},
   "source": [
    "In the validation/test loop, the prediction is first obtained through the model.generate() function, and then both the prediction and the correct label are processed into the text list format accepted by the rouge library (here I replaced the -100 in the tag sequence with the pad token ID for easy decoding by the word separator). Finally, it is sent to the rouge library to calculate each ROUGE value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "640a2861",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "def test_loop(dataloader, model):\n",
    "\n",
    "    preds, labels = [], []\n",
    "    \n",
    "    model.eval()\n",
    "    for batch_data in tqdm(dataloader):\n",
    "        # batch_data = batch_data.to(device)\n",
    "        batch_data = {k: v.to(device) for k, v in batch_data.items()}\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = model.generate(\n",
    "                batch_data[\"input_ids\"],\n",
    "                attention_mask=batch_data[\"attention_mask\"],\n",
    "                max_length=max_target_length,\n",
    "                num_beams=4,\n",
    "                no_repeat_ngram_size=2,\n",
    "            ).cpu().numpy()\n",
    "        if isinstance(generated_tokens, tuple):\n",
    "            generated_tokens = generated_tokens[0]\n",
    "        label_tokens = batch_data[\"labels\"].cpu().numpy()\n",
    "\n",
    "        decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        label_tokens = np.where(label_tokens != -100, label_tokens, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(label_tokens, skip_special_tokens=True)\n",
    "\n",
    "        preds += [' '.join(pred.strip()) for pred in decoded_preds]\n",
    "        labels += [' '.join(label.strip()) for label in decoded_labels]\n",
    "    scores = rouge.get_scores(hyps=preds, refs=labels, avg=True)\n",
    "    result = {key: value['f'] * 100 for key, value in scores.items()}\n",
    "    result['avg'] = np.mean(list(result.values()))\n",
    "    print(f\"Rouge1: {result['rouge-1']:>0.2f} Rouge2: {result['rouge-2']:>0.2f} RougeL: {result['rouge-l']:>0.2f}\\n\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fc7af19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1.321175: 100%|██████████| 463/463 [01:44<00:00,  4.43it/s]\n",
      "100%|██████████| 125/125 [05:13<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge1: 89.48 Rouge2: 73.70 RougeL: 86.16\n",
      "\n",
      "{'rouge-1': 89.47554793687289, 'rouge-2': 73.69927137313994, 'rouge-l': 86.15641815026342, 'avg': 83.11041248675875}\n",
      "saving new weights...\n",
      "\n",
      "Epoch 2/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1.176730: 100%|██████████| 463/463 [01:34<00:00,  4.90it/s]\n",
      "100%|██████████| 125/125 [05:29<00:00,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge1: 89.62 Rouge2: 73.58 RougeL: 86.15\n",
      "\n",
      "{'rouge-1': 89.62083377597432, 'rouge-2': 73.57828468062392, 'rouge-l': 86.15466260770117, 'avg': 83.11792702143313}\n",
      "saving new weights...\n",
      "\n",
      "Epoch 3/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1.089468: 100%|██████████| 463/463 [01:36<00:00,  4.80it/s]\n",
      "100%|██████████| 125/125 [05:02<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge1: 90.92 Rouge2: 75.89 RougeL: 87.55\n",
      "\n",
      "{'rouge-1': 90.92075783593174, 'rouge-2': 75.89080108867714, 'rouge-l': 87.55392718140361, 'avg': 84.78849536867084}\n",
      "saving new weights...\n",
      "\n",
      "Epoch 4/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1.024801: 100%|██████████| 463/463 [01:34<00:00,  4.89it/s]\n",
      "100%|██████████| 125/125 [05:10<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge1: 91.29 Rouge2: 76.59 RougeL: 87.69\n",
      "\n",
      "{'rouge-1': 91.28626754635513, 'rouge-2': 76.58819912750535, 'rouge-l': 87.68540459788944, 'avg': 85.18662375724996}\n",
      "saving new weights...\n",
      "\n",
      "Epoch 5/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.972622: 100%|██████████| 463/463 [01:44<00:00,  4.44it/s]\n",
      "100%|██████████| 125/125 [05:30<00:00,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge1: 92.06 Rouge2: 77.38 RougeL: 88.83\n",
      "\n",
      "{'rouge-1': 92.05575328959725, 'rouge-2': 77.38466798678982, 'rouge-l': 88.8258129219898, 'avg': 86.08874473279229}\n",
      "saving new weights...\n",
      "\n",
      "Epoch 6/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.929744: 100%|██████████| 463/463 [01:35<00:00,  4.83it/s]\n",
      "100%|██████████| 125/125 [05:09<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge1: 92.18 Rouge2: 77.30 RougeL: 88.93\n",
      "\n",
      "{'rouge-1': 92.17624635772465, 'rouge-2': 77.2961076103515, 'rouge-l': 88.93319646753444, 'avg': 86.13518347853687}\n",
      "saving new weights...\n",
      "\n",
      "Epoch 7/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.893528: 100%|██████████| 463/463 [01:34<00:00,  4.90it/s]\n",
      "100%|██████████| 125/125 [05:10<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge1: 92.17 Rouge2: 77.56 RougeL: 89.01\n",
      "\n",
      "{'rouge-1': 92.17484115981007, 'rouge-2': 77.56128487013223, 'rouge-l': 89.00799507530614, 'avg': 86.24804036841614}\n",
      "saving new weights...\n",
      "\n",
      "Epoch 8/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.862917: 100%|██████████| 463/463 [01:36<00:00,  4.81it/s]\n",
      "100%|██████████| 125/125 [05:09<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge1: 91.90 Rouge2: 77.26 RougeL: 88.80\n",
      "\n",
      "{'rouge-1': 91.90016703860374, 'rouge-2': 77.26398998120823, 'rouge-l': 88.79812266692937, 'avg': 85.98742656224711}\n",
      "Epoch 9/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.837093: 100%|██████████| 463/463 [01:36<00:00,  4.82it/s]\n",
      "100%|██████████| 125/125 [05:09<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge1: 92.09 Rouge2: 77.26 RougeL: 88.74\n",
      "\n",
      "{'rouge-1': 92.09392402074845, 'rouge-2': 77.26008367393649, 'rouge-l': 88.73735772338159, 'avg': 86.03045513935551}\n",
      "Epoch 10/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.815616: 100%|██████████| 463/463 [01:36<00:00,  4.81it/s]\n",
      "100%|██████████| 125/125 [05:10<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge1: 92.10 Rouge2: 77.44 RougeL: 88.71\n",
      "\n",
      "{'rouge-1': 92.10007865979176, 'rouge-2': 77.43745142714089, 'rouge-l': 88.71038435666864, 'avg': 86.0826381478671}\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "learning_rate = 1e-7\n",
    "epoch_num = 10\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=epoch_num*len(train_dataloader),\n",
    ")\n",
    "\n",
    "total_loss = 0.\n",
    "best_avg_rouge = 0.\n",
    "for t in range(epoch_num):\n",
    "    print(f\"Epoch {t+1}/{epoch_num}\\n-------------------------------\")\n",
    "    total_loss = train_loop(train_dataloader, model, optimizer, lr_scheduler, t+1, total_loss)\n",
    "    valid_rouge = test_loop(valid_dataloader, model)\n",
    "    print(valid_rouge)\n",
    "    rouge_avg = valid_rouge['avg']\n",
    "    if rouge_avg > best_avg_rouge:\n",
    "        best_avg_rouge = rouge_avg\n",
    "        print('saving new weights...\\n')\n",
    "        torch.save(model.state_dict(), f'epoch_{t+1}_valid_rouge_{rouge_avg:0.4f}_model_weights.bin')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40026d51",
   "metadata": {},
   "source": [
    "## Step 5 Test model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45014ce",
   "metadata": {},
   "source": [
    "After training, we load the model weights that perform best on the validation set, report their performance on the test set, and save the model predictions to a file.\n",
    "\n",
    "Since AutoModelForSeq2SeqLM encapsulates the entire decoding process, we just need to call generate() function to automatically find the best token ID sequence through beam search, Therefore, at last, you only need to convert the token ID sequence into text using the word divider to obtain the generated summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb5bf5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataloader = DataLoader(test_data, batch_size = 4, shuffle = False, collate_fn = collote_fn)\n",
    "model.load_state_dict(torch.load('epoch_7_valid_rouge_86.2480_model_weights.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66110351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [02:53<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rouge1: 91.87 Rouge2: 77.62 RougeL: 88.52\n",
      "\n",
      "saving predicted results...\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    print('evaluating on test set...')\n",
    "    sources, preds, labels = [], [], []\n",
    "    for batch_data in tqdm(test_dataloader):\n",
    "        batch_data = batch_data.to(device)\n",
    "        generated_tokens = model.generate(\n",
    "            batch_data[\"input_ids\"],\n",
    "            attention_mask=batch_data[\"attention_mask\"],\n",
    "            max_length=max_target_length,\n",
    "            num_beams=4,\n",
    "            no_repeat_ngram_size=2,\n",
    "        )\n",
    "\n",
    "        generated_tokens = generated_tokens.cpu().numpy()\n",
    "        label_tokens = batch_data[\"labels\"].cpu().numpy()\n",
    "\n",
    "        decoded_sources = tokenizer.batch_decode(\n",
    "            batch_data[\"input_ids\"].cpu().numpy(), \n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "        decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        label_tokens = np.where(label_tokens != -100, label_tokens, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(label_tokens, skip_special_tokens=True)\n",
    "\n",
    "        sources += [source.strip() for source in decoded_sources]\n",
    "        preds += [pred.strip() for pred in decoded_preds]\n",
    "        labels += [label.strip() for label in decoded_labels]\n",
    "    scores = rouge.get_scores(\n",
    "        hyps=[' '.join(pred) for pred in preds], \n",
    "        refs=[' '.join(label) for label in labels], \n",
    "        avg=True\n",
    "    )\n",
    "    rouges = {key: value['f'] * 100 for key, value in scores.items()}\n",
    "    rouges['avg'] = np.mean(list(rouges.values()))\n",
    "    print(f\"Test Rouge1: {rouges['rouge-1']:>0.2f} Rouge2: {rouges['rouge-2']:>0.2f} RougeL: {rouges['rouge-l']:>0.2f}\\n\")\n",
    "    results = []\n",
    "    print('saving predicted results...')\n",
    "    for source, pred, label in zip(sources, preds, labels):\n",
    "        results.append({\n",
    "            \"document\": source, \n",
    "            \"prediction\": pred, \n",
    "            \"summarization\": label\n",
    "        })\n",
    "    with open('post_bart_large_text_summarizer.json', 'wt', encoding='utf-8') as f:\n",
    "        for exapmle_result in results:\n",
    "            f.write(json.dumps(exapmle_result, ensure_ascii=False) + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8a1841",
   "metadata": {},
   "source": [
    "The fine-tuned inference produced by the json file is saved as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "178cb46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "model_name = 'bart-large-text-summarizer'\n",
    "\n",
    "results = []\n",
    "for idx in range(len(test_data)):\n",
    "    try:\n",
    "        dialogue, reference_summary = test_data[idx]\n",
    "        predicted_summary = predict_summary(dialogue, model, tokenizer)\n",
    "        results.append({\n",
    "            \"Dialogue\": dialogue,\n",
    "            \"Reference Summary\": reference_summary,\n",
    "            \"Predicted Summary\": predicted_summary\n",
    "        })\n",
    "    except ValueError as e:\n",
    "        print(f\"Error at index {idx}: {e}\")\n",
    "\n",
    "\n",
    "# 保存到CSV\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(f\"post_{model_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb09fa6f",
   "metadata": {},
   "source": [
    "Remove a piece of data for viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d91db491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjective: The patient, who had an emergency caesarean delivery at 39 weeks due to fetal distress, reports no postpartum complications. She underwent saline contrast sonohysterography 6 months post-cavear section, revealing a small indentation in the scar and a remaining myometrium of 7.5 mm. At 11 weeks, she underwent a transvaginal ultrasound, which showed a duplex pregnancy with one viable intrauterine fetus and normal anatomy and placenta. A small gestational sac (8 mm) with a yolk sac without an embryo was noted, but there was no extensive vascularity surrounding the sac. During subsequent ultrasounds at 18, 22, and 30 weeks of gestation, the ectopic sac was not visualized. No contraindications for vaginal delivery were noted. The thickness of the lower uterine segment (LUS) was 4.9 mm (Fig.\n"
     ]
    }
   ],
   "source": [
    "def predict_summary(input_text, model, tokenizer, device='cuda'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=1024, truncation=True, padding=\"max_length\")\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_length=512,\n",
    "        num_beams=10,\n",
    "        no_repeat_ngram_size=2,\n",
    "        early_stopping=False\n",
    "    )\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "    return summary\n",
    "\n",
    "# 使用函数\n",
    "input_text = \"Doctor: Hello, I remember you had an emergency caesarean delivery at 39 weeks due to fetal distress. How have you been since then? Any postpartum complications? Patient: Hi, Doctor. I've been doing well since the delivery. No complications, thankfully. Doctor: That's good to hear. As part of our ongoing study on 'Vaginal delivery after caesarean section', you underwent a saline contrast sonohysterography 6 months after the caesarean section. The results showed a small indentation in your caesarean scar, and the remaining myometrium over the defect was 7.5 mm (Fig. ). Patient: Oh, I see. What does that mean for my current pregnancy? Doctor: At around 11 weeks, you had a dating scan with no remarks. Then, you came for a transvaginal ultrasound examination at around 13 weeks asc part of our study. The scan revealed a duplex pregnancy with one viable intrauterine fetus with normal anatomy and placenta located high on the anterior wall. A small gestational sac (8 mm) with a yolk sac without an embryo was located in the caesarean scar (Fig. ). There was no extensive vascularity surrounding the sac, and you were asymptomatic. Patient: Yes, that's right. I didn't feel any discomfort or symptoms. Doctor: We informed you that there wasn't enough evidence to advise a specific management for this condition. After discussion with you and your husband, expectant management was chosen with a new ultrasound examination scheduled after 5 weeks. Patient: Yes, we decided to wait and see how things would progress. Doctor: You came to our ultrasound department at 18 weeks, 22 weeks, and 30 weeks of gestation. Throughout this time, you remained asymptomatic. The ectopic gestational sac was not visualized with transvaginal or transabdominal scans at the 18 weeks examination (Fig. ). The niche in the scar and the thickness of the thinnest part of the remaining myometrium appeared unchanged at all visits. Patient: That's a relief. How's the intrauterine pregnancy developing? Doctor: The intrauterine pregnancy developed normally with no signs of abnormal placentation. At 30 weeks of gestation, the ultrasound appearance of the scar area did not indicate any contraindications for vaginal delivery. The thickness of the lower uterine segment (LUS) was 4.9 mm (Fig. ). Patient: So, I can have a vaginal delivery this time? Doctor: Yes, in agreement with you, we've planned for a vaginal delivery. The staff of the labor ward has been fully informed and prepared for your case. Patient: That's great news! Thank you, Doctor. Doctor: You're welcome. You'll be admitted to the labor ward when the time comes. Please continue to monitor your symptoms and reach out if you have any concerns. Good luck with the rest of your pregnancy. Patient: Thank you so much, Doctor. I appreciate your help and guidance throughout this process.\"\n",
    "summary = predict_summary(input_text, model, tokenizer, device)\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
