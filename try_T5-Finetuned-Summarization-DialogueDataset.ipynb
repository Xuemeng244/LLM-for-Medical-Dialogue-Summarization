{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a44020e-a8c9-47d5-b77b-e20dd96e4944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac89ca69-7307-4180-888b-b470de1ceb49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = t.cuda.device_count()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be980832-fda5-450b-b934-b87954cafd34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install datasets rouge_score torchmetrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b53dc897-d035-489c-8a15-676b235ef123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jie/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import *\n",
    "from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForLanguageModeling, Seq2SeqTrainer, Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "086f4e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MedicalDialogueDataset(Dataset):\n",
    "    def __init__(self, split, percent=100, seed=42):  # 添加seed参数，默认值为42\n",
    "        # 加载数据集\n",
    "        ds = load_dataset(\"omi-health/medical-dialogue-to-soap-summary\", split=split)\n",
    "        \n",
    "        # 移除不需要的列\n",
    "        columns_to_remove = ['messages', 'prompt']\n",
    "        ds = ds.remove_columns(columns_to_remove)\n",
    "        \n",
    "        # 替换换行符并重命名列\n",
    "        ds = ds.rename_column('soap', 'summary')\n",
    "        \n",
    "        # 添加ID和格式化摘要\n",
    "        ds = ds.map(self.add_id, with_indices=True)\n",
    "        ds = ds.map(self.format_summary)\n",
    "        \n",
    "        # 如果需要子集，先随机打乱，再选择对应的百分比\n",
    "        if percent < 100:\n",
    "            ds = ds.shuffle(seed=seed).select(range(int(percent / 100.0 * len(ds))))\n",
    "        \n",
    "        self.data = ds\n",
    "    \n",
    "    def add_id(self, example, idx):\n",
    "        example['id'] = str(idx)\n",
    "        return example\n",
    "    \n",
    "    def format_summary(self, example):\n",
    "        example['summary'] = example['summary'].replace('S: ', 'Subjective: ')\n",
    "        example['summary'] = example['summary'].replace('O: ', 'Objective: ')\n",
    "        example['summary'] = example['summary'].replace('A: ', 'Assessment: ')\n",
    "        example['summary'] = example['summary'].replace('P: ', 'Plan: ')\n",
    "        return example\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]  # 获取索引对应的数据项\n",
    "        ordered_item = {'id': item['id']}  # 创建一个新字典，并首先加入'id'\n",
    "        ordered_item.update({k: item[k] for k in item if k != 'id'})  # 添加其他字段，排除'id'\n",
    "        # return item['dialogue'], item['summary'] \n",
    "        return ordered_item\n",
    "\n",
    "# 创建不同百分比的训练数据集实例\n",
    "# train_data = MedicalDialogueDataset('train', percent=20, seed=42)\n",
    "# train_data = MedicalDialogueDataset('train', percent=50, seed=42)\n",
    "train_data = MedicalDialogueDataset('train', percent=100, seed=42)  \n",
    "\n",
    "valid_data = MedicalDialogueDataset('validation')\n",
    "test_data = MedicalDialogueDataset('test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a743f4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 示例初始化\n",
    "# train_data = MedicalDialogueDataset('train')\n",
    "# valid_data = MedicalDialogueDataset('validation')\n",
    "# test_data = MedicalDialogueDataset('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60c941c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: 9250\n",
      "valid set size: 500\n",
      "test set size: 250\n",
      "{'id': '0', 'dialogue': \"Doctor: Hello, how can I help you today?\\nPatient: My son has been having some issues with speech and development. He's 13 years old now.\\nDoctor: I see. Can you tell me more about his symptoms? Does he have any issues with muscle tone or hypotonia?\\nPatient: No, he doesn't have hypotonia. But he has mild to moderate speech and developmental delay, and he's been diagnosed with attention deficit disorder.\\nDoctor: Thank you for sharing that information. We'll run some tests, including an MRI, to get a better understanding of your son's condition. \\n(After the tests)\\nDoctor: The MRI results are in, and I'm glad to say that there are no structural brain anomalies. However, I did notice some physical characteristics. Does your son have any facial features like retrognathia, mild hypertelorism, or a slightly elongated philtrum and thin upper lip?\\nPatient: Yes, he has all of those features. His hands are also broad and short. And his feet have mild syndactyly of the second and third toe, with a sandal gap in both feet.\\nDoctor: Thank you for confirming that. We also conducted Whole Exome Sequencing (WES) analyses, and we found a de novo frameshift variant in his genetic makeup. Specifically, it's Chr1(GRCh37):g.244217335del, NM_205768.2(ZBTB18):c.259del(p.(Leu87Cysfs*21)). This leads to a premature termination codon located more than 400 codons upstream of the canonical termination codon.\\nPatient: What does that mean for my son?\\nDoctor: This genetic variant may be contributing to your son's speech, developmental delay, and attention deficit disorder. It's important that we continue monitoring his progress and provide appropriate support for his development.\\nPatient: What should we do for follow-up?\\nDoctor: Regular visits with a speech and language therapist, an occupational therapist, and a psychologist can help address your son's developmental and attention deficit disorder needs. I will also recommend regular check-ups with me to monitor his growth and overall health.\\nPatient: Thank you, doctor. We will follow your recommendations and keep an eye on his progress.\", 'summary': \"Subjective: The patient's mother reports that her 13-year-old son has mild to moderate speech and developmental delays and has been diagnosed with attention deficit disorder. She denies any issues with muscle tone or hypotonia. The patient also exhibits certain physical characteristics, including retrognathia, mild hypertelorism, an elongated philtrum, thin upper lip, broad and short hands, mild syndactyly of the second and third toes, and a sandal gap in both feet.\\nObjective: An MRI of the brain showed no structural anomalies. Whole Exome Sequencing (WES) revealed a de novo frameshift variant Chr1(GRCh37):g.244217335del, NM_205768.2(ZBTB18):c.259del(p.(Leu87Cysfs*21)), indicating a premature termination codon located more than 400 codons upstream of the canonical termination codon.\\nAssessment: The primary diagnosis is a genetic disorder associated with the identified frameshift mutation, which likely contributes to the patient's speech and developmental delays and attention deficit disorder. The physical characteristics and genetic findings suggest a specific syndrome, which needs further correlation with clinical findings and genetic counseling.\\nPlan: The management plan includes regular follow-up visits with a speech and language therapist, an occupational therapist, and a psychologist to support the patient's developmental needs and address his attention deficit disorder. Regular medical check-ups will monitor his growth and overall health. Genetic counseling for the family is also recommended to discuss the implications of the genetic findings and potential familial inheritance.\", 'messages_nosystem': [{'role': 'user', 'content': \"You are an expert medical professor assisting in the creation of medically accurate SOAP summaries. Please ensure the response follows the structured format: S:, O:, A:, P: without using markdown or special formatting. Create a Medical SOAP note summary from the dialogue, following these guidelines:\\n    S (Subjective): Summarize the patient's reported symptoms, including chief complaint and relevant history. Rely on the patient's statements as the primary source and ensure standardized terminology.\\n    O (Objective): Highlight critical findings such as vital signs, lab results, and imaging, emphasizing important details like the side of the body affected and specific dosages. Include normal ranges where relevant.\\n    A (Assessment): Offer a concise assessment combining subjective and objective data. State the primary diagnosis and any differential diagnoses, noting potential complications and the prognostic outlook.\\n    P (Plan): Outline the management plan, covering medication, diet, consultations, and education. Ensure to mention necessary referrals to other specialties and address compliance challenges.\\n    Considerations: Compile the report based solely on the transcript provided. Maintain confidentiality and document sensitively. Use concise medical jargon and abbreviations for effective doctor communication.\\n    Please format the summary in a clean, simple list format without using markdown or bullet points. Use 'S:', 'O:', 'A:', 'P:' directly followed by the text. Avoid any styling or special characters. ### Dialogue:\\nDoctor: Hello, how can I help you today?\\nPatient: My son has been having some issues with speech and development. He's 13 years old now.\\nDoctor: I see. Can you tell me more about his symptoms? Does he have any issues with muscle tone or hypotonia?\\nPatient: No, he doesn't have hypotonia. But he has mild to moderate speech and developmental delay, and he's been diagnosed with attention deficit disorder.\\nDoctor: Thank you for sharing that information. We'll run some tests, including an MRI, to get a better understanding of your son's condition. \\n(After the tests)\\nDoctor: The MRI results are in, and I'm glad to say that there are no structural brain anomalies. However, I did notice some physical characteristics. Does your son have any facial features like retrognathia, mild hypertelorism, or a slightly elongated philtrum and thin upper lip?\\nPatient: Yes, he has all of those features. His hands are also broad and short. And his feet have mild syndactyly of the second and third toe, with a sandal gap in both feet.\\nDoctor: Thank you for confirming that. We also conducted Whole Exome Sequencing (WES) analyses, and we found a de novo frameshift variant in his genetic makeup. Specifically, it's Chr1(GRCh37):g.244217335del, NM_205768.2(ZBTB18):c.259del(p.(Leu87Cysfs*21)). This leads to a premature termination codon located more than 400 codons upstream of the canonical termination codon.\\nPatient: What does that mean for my son?\\nDoctor: This genetic variant may be contributing to your son's speech, developmental delay, and attention deficit disorder. It's important that we continue monitoring his progress and provide appropriate support for his development.\\nPatient: What should we do for follow-up?\\nDoctor: Regular visits with a speech and language therapist, an occupational therapist, and a psychologist can help address your son's developmental and attention deficit disorder needs. I will also recommend regular check-ups with me to monitor his growth and overall health.\\nPatient: Thank you, doctor. We will follow your recommendations and keep an eye on his progress.\"}, {'role': 'assistant', 'content': \"S: The patient's mother reports that her 13-year-old son has mild to moderate speech and developmental delays and has been diagnosed with attention deficit disorder. She denies any issues with muscle tone or hypotonia. The patient also exhibits certain physical characteristics, including retrognathia, mild hypertelorism, an elongated philtrum, thin upper lip, broad and short hands, mild syndactyly of the second and third toes, and a sandal gap in both feet.\\nO: An MRI of the brain showed no structural anomalies. Whole Exome Sequencing (WES) revealed a de novo frameshift variant Chr1(GRCh37):g.244217335del, NM_205768.2(ZBTB18):c.259del(p.(Leu87Cysfs*21)), indicating a premature termination codon located more than 400 codons upstream of the canonical termination codon.\\nA: The primary diagnosis is a genetic disorder associated with the identified frameshift mutation, which likely contributes to the patient's speech and developmental delays and attention deficit disorder. The physical characteristics and genetic findings suggest a specific syndrome, which needs further correlation with clinical findings and genetic counseling.\\nP: The management plan includes regular follow-up visits with a speech and language therapist, an occupational therapist, and a psychologist to support the patient's developmental needs and address his attention deficit disorder. Regular medical check-ups will monitor his growth and overall health. Genetic counseling for the family is also recommended to discuss the implications of the genetic findings and potential familial inheritance.\"}]}\n"
     ]
    }
   ],
   "source": [
    "print(f'train set size: {len(train_data)}')\n",
    "print(f'valid set size: {len(valid_data)}')\n",
    "print(f'test set size: {len(test_data)}')\n",
    "print(next(iter(train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae6e66ca-0c96-4e0f-8345-bbe46ef166fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gauravkoradiya/T5-Finetuned-Summarization-DialogueDataset\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bdca55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: tensor([[7582,   10,  363,  ...,    0,    0,    0]])\n",
      "Tokens: ['▁Doctor', ':', '▁What', '▁brings', '▁you', '▁back', '▁into', '▁the', '▁clinic', '▁today', ',', '▁miss', '?', '▁Patient', ':', '▁I', '▁came', '▁in', '▁for', '▁', 'a', '▁refill', '▁of', '▁my', '▁blood', '▁pressure', '▁medicine', '.', '▁Doctor', ':', '▁It', '▁looks', '▁like', '▁Doctor', '▁Kumar', '▁followed', '▁up', '▁with', '▁you', '▁last', '▁time', '▁regarding', '▁your', '▁hyper', 'tension', ',', '▁osteo', 'arth', 'riti', 's', ',', '▁osteo', 'p', 'o', 'ros', 'is', ',', '▁hypo', 't', 'hyroid', 'is', 'm', ',', '▁allergic', '▁', 'r', 'hin', 'it', 'is', '▁and', '▁kidney', '▁stones', '.', '▁Have', '▁you', '▁noticed', '▁any', '▁changes', '▁or', '▁do', '▁you', '▁have', '▁any', '▁concerns', '▁regarding', '▁these', '▁issues', '?', '▁Patient', ':', '▁No', '.', '▁Doctor', ':', '▁Have', '▁you', '▁had', '▁any', '▁fever', '▁or', '▁chill', 's', ',', '▁cough', ',', '▁congestion', ',', '▁nausea', ',', '▁vomiting', ',', '▁chest', '▁pain', ',', '▁chest', '▁pressure', '?', 'P', 'a', 'tient', ':', '▁No', '.', '▁Doctor', ':', '▁Great', '.', '▁Also', ',', '▁for', '▁our', '▁records', ',', '▁how', '▁old', '▁are', '▁you', '▁and', '▁what', '▁race', '▁do', '▁you', '▁identify', '▁yourself', '▁as', '?', 'P', 'a', 'tient', ':', '▁I', '▁am', '▁seven', 't', 'y', '▁six', '▁years', '▁old', '▁and', '▁identify', '▁as', '▁', 'a', '▁white', '▁female', '.', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "dialogue = \"Doctor: What brings you back into the clinic today, miss? Patient: I came in for a refill of my blood pressure medicine. Doctor: It looks like Doctor Kumar followed up with you last time regarding your hypertension, osteoarthritis, osteoporosis, hypothyroidism, allergic rhinitis and kidney stones.  Have you noticed any changes or do you have any concerns regarding these issues? Patient: No. Doctor: Have you had any fever or chills, cough, congestion, nausea, vomiting, chest pain, chest pressure?Patient: No. Doctor: Great. Also, for our records, how old are you and what race do you identify yourself as?Patient: I am seventy six years old and identify as a white female.\"\n",
    "inputs = tokenizer(dialogue, return_tensors=\"pt\", max_length=1024, truncation=True, padding=\"max_length\")\n",
    "summary = \"The patient is a 76-year-old white female who presents to the clinic today originally for hypertension and a med check.  She has a history of hypertension, osteoarthritis, osteoporosis, hypothyroidism, allergic rhinitis and kidney stones.  Since her last visit she has been followed by Dr. Kumar.  Those issues are stable.  She has had no fever or chills, cough, congestion, nausea, vomiting, chest pain, chest pressure.\"\n",
    "# 对目标摘要进行编码\n",
    "targets = tokenizer(summary, return_tensors=\"pt\", max_length=1024, truncation=True, padding=\"max_length\")\n",
    "# 打印输入的令牌ID和对应的文本表示\n",
    "print('Token IDs:', inputs['input_ids'])\n",
    "print('Tokens:', tokenizer.convert_ids_to_tokens(inputs['input_ids'][0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f418b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d1a2e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jie/.local/lib/python3.8/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForSeq2SeqLM, AdamW\n",
    "\n",
    "max_input_length = 512\n",
    "max_target_length = 256\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"gauravkoradiya/T5-Finetuned-Summarization-DialogueDataset\").half()\n",
    "model = model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "523d179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collote_fn(batch_samples):\n",
    "    batch_inputs, batch_targets = [], []\n",
    "    for sample in batch_samples:\n",
    "        batch_inputs.append(sample['dialogue'])\n",
    "        batch_targets.append(sample['summary'])\n",
    "    batch_data = tokenizer(\n",
    "        batch_inputs, \n",
    "        padding=True, \n",
    "        max_length=max_input_length,\n",
    "        truncation=True, \n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            batch_targets, \n",
    "            padding=True, \n",
    "            max_length=max_target_length,\n",
    "            truncation=True, \n",
    "            return_tensors=\"pt\"\n",
    "        )[\"input_ids\"]\n",
    "        batch_data['decoder_input_ids'] = model.prepare_decoder_input_ids_from_labels(labels)\n",
    "        end_token_index = torch.where(labels == tokenizer.eos_token_id)[1]\n",
    "        for idx, end_idx in enumerate(end_token_index):\n",
    "            labels[idx][end_idx+1:] = -100\n",
    "        batch_data['labels'] = labels\n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a4c2710",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=4, shuffle=True, collate_fn=collote_fn)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=4, shuffle=False, collate_fn=collote_fn)\n",
    "test_dataloader = DataLoader(test_data,batch_size=4,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abeed6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Summaries: 100%|██████████| 63/63 [01:02<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE Scores: {'rouge1': 0.14346195300443879, 'rouge2': 0.06140384692675339, 'rougeL': 0.10495451612662542}\n",
      "Pre-training predictions and ROUGE scores saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# 初始化 ROUGE 评分器\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "def predict_summary(dialogue, model, tokenizer):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(dialogue, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "        outputs = model.generate(inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], max_length=64)\n",
    "        summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "results = []\n",
    "rouge_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "for batch in tqdm(test_dataloader, desc=\"Generating Summaries\"):\n",
    "    dialogues = batch['dialogue']\n",
    "    reference_summaries = batch['summary']\n",
    "    \n",
    "    for dialogue, reference_summary in zip(dialogues, reference_summaries):\n",
    "        predicted_summary = predict_summary(dialogue, model, tokenizer)\n",
    "        scores = scorer.score(reference_summary, predicted_summary)\n",
    "        results.append({\n",
    "            \"Dialogue\": dialogue,\n",
    "            \"Reference Summary\": reference_summary,\n",
    "            \"Predicted Summary\": predicted_summary,\n",
    "            \"ROUGE-1\": scores['rouge1'].fmeasure,\n",
    "            \"ROUGE-2\": scores['rouge2'].fmeasure,\n",
    "            \"ROUGE-L\": scores['rougeL'].fmeasure\n",
    "        })\n",
    "\n",
    "        # Accumulate scores\n",
    "        rouge_scores['rouge1'].append(scores['rouge1'].fmeasure)\n",
    "        rouge_scores['rouge2'].append(scores['rouge2'].fmeasure)\n",
    "        rouge_scores['rougeL'].append(scores['rougeL'].fmeasure)\n",
    "\n",
    "# 计算平均 ROUGE 分数\n",
    "average_scores = {key: sum(values) / len(values) for key, values in rouge_scores.items()}\n",
    "print(\"Average ROUGE Scores:\", average_scores)\n",
    "\n",
    "# 保存到 JSON 文件\n",
    "with open('pre_T5_finetuned_summarization_DialogueDataset.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Pre-training predictions and ROUGE scores saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aef5a302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MedicalDialogueDataset(Dataset):\n",
    "    def __init__(self, split, percent=100, seed=42):  # 添加seed参数，默认值为42\n",
    "        # 加载数据集\n",
    "        ds = load_dataset(\"omi-health/medical-dialogue-to-soap-summary\", split=split)\n",
    "        \n",
    "        # 移除不需要的列\n",
    "        columns_to_remove = ['messages', 'prompt']\n",
    "        ds = ds.remove_columns(columns_to_remove)\n",
    "        \n",
    "        # 替换换行符并重命名列\n",
    "        ds = ds.rename_column('soap', 'summary')\n",
    "        \n",
    "        # 添加ID和格式化摘要\n",
    "        ds = ds.map(self.add_id, with_indices=True)\n",
    "        ds = ds.map(self.format_summary)\n",
    "        \n",
    "        # 如果需要子集，先随机打乱，再选择对应的百分比\n",
    "        if percent < 100:\n",
    "            ds = ds.shuffle(seed=seed).select(range(int(percent / 100.0 * len(ds))))\n",
    "        \n",
    "        self.data = ds\n",
    "    \n",
    "    def add_id(self, example, idx):\n",
    "        example['id'] = str(idx)\n",
    "        return example\n",
    "    \n",
    "    def format_summary(self, example):\n",
    "        example['summary'] = example['summary'].replace('S: ', 'Subjective: ')\n",
    "        example['summary'] = example['summary'].replace('O: ', 'Objective: ')\n",
    "        example['summary'] = example['summary'].replace('A: ', 'Assessment: ')\n",
    "        example['summary'] = example['summary'].replace('P: ', 'Plan: ')\n",
    "        return example\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]  # 获取索引对应的数据项\n",
    "        ordered_item = {'id': item['id']}  # 创建一个新字典，并首先加入'id'\n",
    "        ordered_item.update({k: item[k] for k in item if k != 'id'})  # 添加其他字段，排除'id'\n",
    "        return item['dialogue'], item['summary'] \n",
    "        # return ordered_item\n",
    "\n",
    "# 创建不同百分比的训练数据集实例\n",
    "# train_data = MedicalDialogueDataset('train', percent=20, seed=42)\n",
    "# train_data = MedicalDialogueDataset('train', percent=50, seed=42)\n",
    "train_data = MedicalDialogueDataset('train', percent=100, seed=42)  \n",
    "\n",
    "valid_data = MedicalDialogueDataset('validation')\n",
    "test_data = MedicalDialogueDataset('test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b48e907d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "model_name = 'pre_T5_finetuned_summarization_DialogueDataset'\n",
    "\n",
    "results = []\n",
    "for idx in range(len(test_data)):\n",
    "    try:\n",
    "        dialogue, reference_summary = test_data[idx]\n",
    "        predicted_summary = predict_summary(dialogue, model, tokenizer)\n",
    "        results.append({\n",
    "            \"Dialogue\": dialogue,\n",
    "            \"Reference Summary\": reference_summary,\n",
    "            \"Predicted Summary\": predicted_summary\n",
    "        })\n",
    "    except ValueError as e:\n",
    "        print(f\"Error at index {idx}: {e}\")\n",
    "\n",
    "\n",
    "# 保存到CSV\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(f\"{model_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21c13859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MedicalDialogueDataset(Dataset):\n",
    "    def __init__(self, split, percent=100, seed=42):  # 添加seed参数，默认值为42\n",
    "        # 加载数据集\n",
    "        ds = load_dataset(\"omi-health/medical-dialogue-to-soap-summary\", split=split)\n",
    "        \n",
    "        # 移除不需要的列\n",
    "        columns_to_remove = ['messages', 'prompt']\n",
    "        ds = ds.remove_columns(columns_to_remove)\n",
    "        \n",
    "        # 替换换行符并重命名列\n",
    "        ds = ds.rename_column('soap', 'summary')\n",
    "        \n",
    "        # 添加ID和格式化摘要\n",
    "        ds = ds.map(self.add_id, with_indices=True)\n",
    "        ds = ds.map(self.format_summary)\n",
    "        \n",
    "        # 如果需要子集，先随机打乱，再选择对应的百分比\n",
    "        if percent < 100:\n",
    "            ds = ds.shuffle(seed=seed).select(range(int(percent / 100.0 * len(ds))))\n",
    "        \n",
    "        self.data = ds\n",
    "    \n",
    "    def add_id(self, example, idx):\n",
    "        example['id'] = str(idx)\n",
    "        return example\n",
    "    \n",
    "    def format_summary(self, example):\n",
    "        example['summary'] = example['summary'].replace('S: ', 'Subjective: ')\n",
    "        example['summary'] = example['summary'].replace('O: ', 'Objective: ')\n",
    "        example['summary'] = example['summary'].replace('A: ', 'Assessment: ')\n",
    "        example['summary'] = example['summary'].replace('P: ', 'Plan: ')\n",
    "        return example\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]  # 获取索引对应的数据项\n",
    "        ordered_item = {'id': item['id']}  # 创建一个新字典，并首先加入'id'\n",
    "        ordered_item.update({k: item[k] for k in item if k != 'id'})  # 添加其他字段，排除'id'\n",
    "        # return item['dialogue'], item['summary'] \n",
    "        return ordered_item\n",
    "\n",
    "# 创建不同百分比的训练数据集实例\n",
    "# train_data = MedicalDialogueDataset('train', percent=20, seed=42)\n",
    "# train_data = MedicalDialogueDataset('train', percent=50, seed=42)\n",
    "train_data = MedicalDialogueDataset('train', percent=100, seed=42)  \n",
    "\n",
    "valid_data = MedicalDialogueDataset('validation')\n",
    "test_data = MedicalDialogueDataset('test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6300f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'decoder_input_ids', 'labels'])\n",
      "batch shape: {'input_ids': torch.Size([4, 512]), 'attention_mask': torch.Size([4, 512]), 'decoder_input_ids': torch.Size([4, 256]), 'labels': torch.Size([4, 256])}\n",
      "{'input_ids': tensor([[ 7582,    10,  8774,  ...,    75,     5,     1],\n",
      "        [ 7582,    10,  8774,  ...,     3, 18167,     1],\n",
      "        [ 7582,    10,  1804,  ...,  6344,   162,     1],\n",
      "        [ 7582,    10,  8774,  ...,  1968,    28,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), 'decoder_input_ids': tensor([[    0, 19237,   757,  ...,     8, 13996,   120],\n",
      "        [    0, 19237,   757,  ...,  4019,  9859,    12],\n",
      "        [    0, 19237,   757,  ..., 17722,  1133,   441],\n",
      "        [    0, 19237,   757,  ...,  1574,  6676,  1047]]), 'labels': tensor([[19237,   757,    10,  ..., 13996,   120,     1],\n",
      "        [19237,   757,    10,  ...,  9859,    12,     1],\n",
      "        [19237,   757,    10,  ...,  1133,   441,     1],\n",
      "        [19237,   757,    10,  ...,  6676,  1047,     1]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jie/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:4016: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "print(batch.keys())\n",
    "print('batch shape:', {k: v.shape for k, v in batch.items()})\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6958203-8697-4929-b4dc-dc242e6a4ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_loop(dataloader, model, optimizer, lr_scheduler, epoch, total_loss):\n",
    "    progress_bar = tqdm(range(len(dataloader)))\n",
    "    progress_bar.set_description(f'loss: {0:>7f}')\n",
    "    finish_batch_num = (epoch-1) * len(dataloader)\n",
    "    \n",
    "    model.train()\n",
    "    for batch, batch_data in enumerate(dataloader, start=1):\n",
    "        batch_data = batch_data.to(device)\n",
    "        outputs = model(**batch_data)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_description(f'loss: {total_loss/(finish_batch_num + batch):>7f}')\n",
    "        progress_bar.update(1)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da0d3fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rouge import Rouge\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "def test_loop(dataloader, model):\n",
    "\n",
    "    preds, labels = [], []\n",
    "    \n",
    "    model.eval()\n",
    "    for batch_data in tqdm(dataloader):\n",
    "        # batch_data = batch_data.to(device)\n",
    "        batch_data = {k: v.to(device) for k, v in batch_data.items()}\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = model.generate(\n",
    "                batch_data[\"input_ids\"],\n",
    "                attention_mask=batch_data[\"attention_mask\"],\n",
    "                max_length=max_target_length,\n",
    "                num_beams=4,\n",
    "                no_repeat_ngram_size=2,\n",
    "            ).cpu().numpy()\n",
    "        if isinstance(generated_tokens, tuple):\n",
    "            generated_tokens = generated_tokens[0]\n",
    "        label_tokens = batch_data[\"labels\"].cpu().numpy()\n",
    "\n",
    "        decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        label_tokens = np.where(label_tokens != -100, label_tokens, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(label_tokens, skip_special_tokens=True)\n",
    "\n",
    "        preds += [' '.join(pred.strip()) for pred in decoded_preds]\n",
    "        labels += [' '.join(label.strip()) for label in decoded_labels]\n",
    "    scores = rouge.get_scores(hyps=preds, refs=labels, avg=True)\n",
    "    result = {key: value['f'] * 100 for key, value in scores.items()}\n",
    "    result['avg'] = np.mean(list(result.values()))\n",
    "    print(f\"Rouge1: {result['rouge-1']:>0.2f} Rouge2: {result['rouge-2']:>0.2f} RougeL: {result['rouge-l']:>0.2f}\\n\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab2d0eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 2.739707: 100%|██████████| 2313/2313 [03:14<00:00, 11.89it/s]\n",
      "100%|██████████| 125/125 [02:09<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge1: 79.74 Rouge2: 61.78 RougeL: 74.81\n",
      "\n",
      "{'rouge-1': 79.74187510297082, 'rouge-2': 61.7799354110579, 'rouge-l': 74.8097408126954, 'avg': 72.11051710890804}\n",
      "saving new weights...\n",
      "\n",
      "Epoch 2/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 2.478676: 100%|██████████| 2313/2313 [02:56<00:00, 13.08it/s]\n",
      "100%|██████████| 125/125 [03:17<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge1: 81.68 Rouge2: 63.78 RougeL: 76.88\n",
      "\n",
      "{'rouge-1': 81.68362783084514, 'rouge-2': 63.77572234136273, 'rouge-l': 76.87560238870094, 'avg': 74.11165085363628}\n",
      "saving new weights...\n",
      "\n",
      "Epoch 3/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 2.362832: 100%|██████████| 2313/2313 [02:55<00:00, 13.21it/s]\n",
      "100%|██████████| 125/125 [03:40<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge1: 84.90 Rouge2: 66.39 RougeL: 80.73\n",
      "\n",
      "{'rouge-1': 84.89851606543183, 'rouge-2': 66.39287697326893, 'rouge-l': 80.72621160294476, 'avg': 77.33920154721517}\n",
      "saving new weights...\n",
      "\n",
      "Epoch 4/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 2.294448: 100%|██████████| 2313/2313 [02:54<00:00, 13.22it/s]\n",
      "100%|██████████| 125/125 [03:48<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge1: 86.75 Rouge2: 68.19 RougeL: 82.37\n",
      "\n",
      "{'rouge-1': 86.75181988155398, 'rouge-2': 68.18772259305422, 'rouge-l': 82.36643121368445, 'avg': 79.10199122943088}\n",
      "saving new weights...\n",
      "\n",
      "Epoch 5/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 2.249262: 100%|██████████| 2313/2313 [02:55<00:00, 13.20it/s]\n",
      "100%|██████████| 125/125 [03:50<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge1: 86.80 Rouge2: 68.25 RougeL: 82.56\n",
      "\n",
      "{'rouge-1': 86.80237289613716, 'rouge-2': 68.24692259330882, 'rouge-l': 82.56467805950022, 'avg': 79.20465784964874}\n",
      "saving new weights...\n",
      "\n",
      "Epoch 6/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 2.217056: 100%|██████████| 2313/2313 [02:55<00:00, 13.21it/s]\n",
      "100%|██████████| 125/125 [03:51<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge1: 87.32 Rouge2: 68.84 RougeL: 83.24\n",
      "\n",
      "{'rouge-1': 87.32293546686417, 'rouge-2': 68.83726403650623, 'rouge-l': 83.24399257108216, 'avg': 79.80139735815085}\n",
      "saving new weights...\n",
      "\n",
      "Epoch 7/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 2.193066: 100%|██████████| 2313/2313 [02:55<00:00, 13.21it/s]\n",
      "100%|██████████| 125/125 [03:53<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge1: 87.32 Rouge2: 68.93 RougeL: 83.20\n",
      "\n",
      "{'rouge-1': 87.32128652971502, 'rouge-2': 68.92914600226251, 'rouge-l': 83.20201587610632, 'avg': 79.81748280269461}\n",
      "saving new weights...\n",
      "\n",
      "Epoch 8/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 2.174754: 100%|██████████| 2313/2313 [02:55<00:00, 13.18it/s]\n",
      "100%|██████████| 125/125 [03:51<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge1: 87.35 Rouge2: 68.86 RougeL: 83.39\n",
      "\n",
      "{'rouge-1': 87.35223027481204, 'rouge-2': 68.86399277660874, 'rouge-l': 83.38772408134467, 'avg': 79.86798237758849}\n",
      "saving new weights...\n",
      "\n",
      "Epoch 9/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 2.160280: 100%|██████████| 2313/2313 [02:57<00:00, 13.06it/s]\n",
      "100%|██████████| 125/125 [03:57<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge1: 87.57 Rouge2: 68.98 RougeL: 83.51\n",
      "\n",
      "{'rouge-1': 87.56547693795686, 'rouge-2': 68.97570791549039, 'rouge-l': 83.51498542646834, 'avg': 80.01872342663853}\n",
      "saving new weights...\n",
      "\n",
      "Epoch 10/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 2.148755: 100%|██████████| 2313/2313 [02:55<00:00, 13.19it/s]\n",
      "100%|██████████| 125/125 [03:54<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge1: 87.56 Rouge2: 68.96 RougeL: 83.55\n",
      "\n",
      "{'rouge-1': 87.56026540456583, 'rouge-2': 68.96217482353994, 'rouge-l': 83.55398947432255, 'avg': 80.0254765674761}\n",
      "saving new weights...\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_scheduler\n",
    "\n",
    "learning_rate = 1e-7\n",
    "epoch_num = 10\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=epoch_num*len(train_dataloader),\n",
    ")\n",
    "\n",
    "total_loss = 0.\n",
    "best_avg_rouge = 0.\n",
    "for t in range(epoch_num):\n",
    "    print(f\"Epoch {t+1}/{epoch_num}\\n-------------------------------\")\n",
    "    total_loss = train_loop(train_dataloader, model, optimizer, lr_scheduler, t+1, total_loss)\n",
    "    valid_rouge = test_loop(valid_dataloader, model)\n",
    "    print(valid_rouge)\n",
    "    rouge_avg = valid_rouge['avg']\n",
    "    if rouge_avg > best_avg_rouge:\n",
    "        best_avg_rouge = rouge_avg\n",
    "        print('saving new weights...\\n')\n",
    "        torch.save(model.state_dict(), f'epoch_{t+1}_valid_rouge_{rouge_avg:0.4f}_model_weights.bin')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bec3d89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9365acfc",
   "metadata": {},
   "source": [
    "## 推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c2df4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_data, batch_size = 4, shuffle = False, collate_fn = collote_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c76f0f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('epoch_10_valid_rouge_80.0255_model_weights.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de10f5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]/home/jie/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:4016: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "100%|██████████| 63/63 [02:10<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Rouge1: 86.67 Rouge2: 69.00 RougeL: 82.55\n",
      "\n",
      "saving predicted results...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    print('evaluating on test set...')\n",
    "    sources, preds, labels = [], [], []\n",
    "    for batch_data in tqdm(test_dataloader):\n",
    "        batch_data = batch_data.to(device)\n",
    "        generated_tokens = model.generate(\n",
    "            batch_data[\"input_ids\"],\n",
    "            attention_mask=batch_data[\"attention_mask\"],\n",
    "            max_length=max_target_length,\n",
    "            num_beams=4,\n",
    "            no_repeat_ngram_size=2,\n",
    "        )\n",
    "\n",
    "        generated_tokens = generated_tokens.cpu().numpy()\n",
    "        label_tokens = batch_data[\"labels\"].cpu().numpy()\n",
    "\n",
    "        decoded_sources = tokenizer.batch_decode(\n",
    "            batch_data[\"input_ids\"].cpu().numpy(), \n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "        decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        label_tokens = np.where(label_tokens != -100, label_tokens, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(label_tokens, skip_special_tokens=True)\n",
    "\n",
    "        sources += [source.strip() for source in decoded_sources]\n",
    "        preds += [pred.strip() for pred in decoded_preds]\n",
    "        labels += [label.strip() for label in decoded_labels]\n",
    "    scores = rouge.get_scores(\n",
    "        hyps=[' '.join(pred) for pred in preds], \n",
    "        refs=[' '.join(label) for label in labels], \n",
    "        avg=True\n",
    "    )\n",
    "    rouges = {key: value['f'] * 100 for key, value in scores.items()}\n",
    "    rouges['avg'] = np.mean(list(rouges.values()))\n",
    "    print(f\"Test Rouge1: {rouges['rouge-1']:>0.2f} Rouge2: {rouges['rouge-2']:>0.2f} RougeL: {rouges['rouge-l']:>0.2f}\\n\")\n",
    "    results = []\n",
    "    print('saving predicted results...')\n",
    "    for source, pred, label in zip(sources, preds, labels):\n",
    "        results.append({\n",
    "            \"document\": source, \n",
    "            \"prediction\": pred, \n",
    "            \"summarization\": label\n",
    "        })\n",
    "    with open('T5_test_data_pred.json', 'wt', encoding='utf-8') as f:\n",
    "        for exapmle_result in results:\n",
    "            f.write(json.dumps(exapmle_result, ensure_ascii=False) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73c0f6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As part of the ongoing study on 'Vaginal delivery after caesarean section', the patient underwent saline contrast sonohysterography 6 months after fetal distress. Results showed a small indentation in the scar, and the remaining myometrium over the defect was 7.5 mm (Fig. 7) at 30 weeks. The ectopic gestational sac was not visualized at the 18 weeks examination.\n"
     ]
    }
   ],
   "source": [
    "def predict_summary(input_text, model, tokenizer, device='cuda'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=1024, truncation=True, padding=\"max_length\")\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_length=512,\n",
    "        num_beams=10,\n",
    "        no_repeat_ngram_size=2,\n",
    "        early_stopping=False\n",
    "    )\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "    return summary\n",
    "\n",
    "# 使用函数\n",
    "input_text = \"Doctor: Hello, I remember you had an emergency caesarean delivery at 39 weeks due to fetal distress. How have you been since then? Any postpartum complications? Patient: Hi, Doctor. I've been doing well since the delivery. No complications, thankfully. Doctor: That's good to hear. As part of our ongoing study on 'Vaginal delivery after caesarean section', you underwent a saline contrast sonohysterography 6 months after the caesarean section. The results showed a small indentation in your caesarean scar, and the remaining myometrium over the defect was 7.5 mm (Fig. ). Patient: Oh, I see. What does that mean for my current pregnancy? Doctor: At around 11 weeks, you had a dating scan with no remarks. Then, you came for a transvaginal ultrasound examination at around 13 weeks asc part of our study. The scan revealed a duplex pregnancy with one viable intrauterine fetus with normal anatomy and placenta located high on the anterior wall. A small gestational sac (8 mm) with a yolk sac without an embryo was located in the caesarean scar (Fig. ). There was no extensive vascularity surrounding the sac, and you were asymptomatic. Patient: Yes, that's right. I didn't feel any discomfort or symptoms. Doctor: We informed you that there wasn't enough evidence to advise a specific management for this condition. After discussion with you and your husband, expectant management was chosen with a new ultrasound examination scheduled after 5 weeks. Patient: Yes, we decided to wait and see how things would progress. Doctor: You came to our ultrasound department at 18 weeks, 22 weeks, and 30 weeks of gestation. Throughout this time, you remained asymptomatic. The ectopic gestational sac was not visualized with transvaginal or transabdominal scans at the 18 weeks examination (Fig. ). The niche in the scar and the thickness of the thinnest part of the remaining myometrium appeared unchanged at all visits. Patient: That's a relief. How's the intrauterine pregnancy developing? Doctor: The intrauterine pregnancy developed normally with no signs of abnormal placentation. At 30 weeks of gestation, the ultrasound appearance of the scar area did not indicate any contraindications for vaginal delivery. The thickness of the lower uterine segment (LUS) was 4.9 mm (Fig. ). Patient: So, I can have a vaginal delivery this time? Doctor: Yes, in agreement with you, we've planned for a vaginal delivery. The staff of the labor ward has been fully informed and prepared for your case. Patient: That's great news! Thank you, Doctor. Doctor: You're welcome. You'll be admitted to the labor ward when the time comes. Please continue to monitor your symptoms and reach out if you have any concerns. Good luck with the rest of your pregnancy. Patient: Thank you so much, Doctor. I appreciate your help and guidance throughout this process.\"\n",
    "summary = predict_summary(input_text, model, tokenizer, device)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1516738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MedicalDialogueDataset(Dataset):\n",
    "    def __init__(self, split, percent=100, seed=42):  # 添加seed参数，默认值为42\n",
    "        # 加载数据集\n",
    "        ds = load_dataset(\"omi-health/medical-dialogue-to-soap-summary\", split=split)\n",
    "        \n",
    "        # 移除不需要的列\n",
    "        columns_to_remove = ['messages', 'prompt']\n",
    "        ds = ds.remove_columns(columns_to_remove)\n",
    "        \n",
    "        # 替换换行符并重命名列\n",
    "        ds = ds.rename_column('soap', 'summary')\n",
    "        \n",
    "        # 添加ID和格式化摘要\n",
    "        ds = ds.map(self.add_id, with_indices=True)\n",
    "        ds = ds.map(self.format_summary)\n",
    "        \n",
    "        # 如果需要子集，先随机打乱，再选择对应的百分比\n",
    "        if percent < 100:\n",
    "            ds = ds.shuffle(seed=seed).select(range(int(percent / 100.0 * len(ds))))\n",
    "        \n",
    "        self.data = ds\n",
    "    \n",
    "    def add_id(self, example, idx):\n",
    "        example['id'] = str(idx)\n",
    "        return example\n",
    "    \n",
    "    def format_summary(self, example):\n",
    "        example['summary'] = example['summary'].replace('S: ', 'Subjective: ')\n",
    "        example['summary'] = example['summary'].replace('O: ', 'Objective: ')\n",
    "        example['summary'] = example['summary'].replace('A: ', 'Assessment: ')\n",
    "        example['summary'] = example['summary'].replace('P: ', 'Plan: ')\n",
    "        return example\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]  # 获取索引对应的数据项\n",
    "        ordered_item = {'id': item['id']}  # 创建一个新字典，并首先加入'id'\n",
    "        ordered_item.update({k: item[k] for k in item if k != 'id'})  # 添加其他字段，排除'id'\n",
    "        return item['dialogue'], item['summary'] \n",
    "        # return ordered_item\n",
    "\n",
    "# 创建不同百分比的训练数据集实例\n",
    "# train_data = MedicalDialogueDataset('train', percent=20, seed=42)\n",
    "# train_data = MedicalDialogueDataset('train', percent=50, seed=42)\n",
    "train_data = MedicalDialogueDataset('train', percent=100, seed=42)  \n",
    "\n",
    "valid_data = MedicalDialogueDataset('validation')\n",
    "test_data = MedicalDialogueDataset('test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "760bbd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "model_name = 'T5-Finetuned-Summarization-DialogueDataset'\n",
    "results = []\n",
    "for idx in range(len(test_data)):  # 遍历整个测试集\n",
    "    dialogue, reference_summary = test_data[idx]\n",
    "    predicted_summary = predict_summary(dialogue, model, tokenizer)\n",
    "    results.append({\n",
    "        \"Dialogue\": dialogue,\n",
    "        \"Reference Summary\": reference_summary,\n",
    "        \"Predicted Summacccry\": predicted_summary\n",
    "    })\n",
    "\n",
    "# 保存到CSV\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(f\"post_{model_name}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
